{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jvd-5uneeUBV"
      },
      "outputs": [],
      "source": [
        "%pip install opendatasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5426418e"
      },
      "source": [
        "## Download and prepare the data\n",
        "\n",
        "Download the dataset and prepare it for use with a SQL database.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "912b5b0d"
      },
      "source": [
        "**Reasoning**:\n",
        "Download the dataset from Kaggle using the opendatasets library and examine the downloaded files.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c32b03c8"
      },
      "outputs": [],
      "source": [
        "import opendatasets as od\n",
        "import os\n",
        "\n",
        "dataset_url = 'https://www.kaggle.com/datasets/lykin22/tiktok-trending-data'\n",
        "od.download(dataset_url)\n",
        "\n",
        "# List the downloaded files\n",
        "dataset_name = dataset_url.split('/')[-1]\n",
        "download_path = f'./{dataset_name}'\n",
        "print(f\"Downloaded dataset to: {download_path}\")\n",
        "print(\"Files in the dataset:\")\n",
        "for root, dirs, files in os.walk(download_path):\n",
        "    for file in files:\n",
        "        print(os.path.join(root, file))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3a5ff09"
      },
      "source": [
        "**Reasoning**:\n",
        "The dataset contains JSON files. To prepare for a SQL database, I will read each JSON file into a pandas DataFrame and then save them as CSV files, which are generally easier to import into SQL databases.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7546e27c"
      },
      "outputs": [],
      "source": [
        "json_files = [f for f in os.listdir(download_path) if f.endswith('.json')]\n",
        "\n",
        "if json_files:\n",
        "    first_json_file = os.path.join(download_path, json_files[0])\n",
        "    print(f\"Inspecting the first few lines of {first_json_file}:\")\n",
        "    with open(first_json_file, 'r', encoding='utf-8') as f:\n",
        "        # Read and print the first 10 lines to get an idea of the structure\n",
        "        for i in range(10):\n",
        "            try:\n",
        "                line = next(f)\n",
        "                print(line.strip())\n",
        "            except StopIteration:\n",
        "                break\n",
        "else:\n",
        "    print(\"No JSON files found in the download directory.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a2fbe28"
      },
      "source": [
        "**Reasoning**:\n",
        "Iterate through the keys of the loaded JSON data, convert each list into a DataFrame, and save each DataFrame as a CSV file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48824024"
      },
      "outputs": [],
      "source": [
        "output_csv_path = './tiktok_csv_data'\n",
        "os.makedirs(output_csv_path, exist_ok=True)\n",
        "\n",
        "json_files = [f for f in os.listdir(download_path) if f.endswith('.json')]\n",
        "\n",
        "for json_file in json_files:\n",
        "    json_filepath = os.path.join(download_path, json_file)\n",
        "    print(f\"Processing {json_filepath}...\")\n",
        "\n",
        "    try:\n",
        "        with open(json_filepath, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        for key, value in data.items():\n",
        "            if isinstance(value, list):\n",
        "                df = pd.DataFrame(value)\n",
        "                csv_filename = f\"{os.path.splitext(json_file)[0]}_{key}.csv\"\n",
        "                csv_filepath = os.path.join(output_csv_path, csv_filename)\n",
        "                df.to_csv(csv_filepath, index=False)\n",
        "                print(f\"Saved {csv_filepath}\")\n",
        "            else:\n",
        "                print(f\"Skipping key '{key}' in {json_file} as it is not a list.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {json_file}: {e}\")\n",
        "\n",
        "print(f\"CSV files saved to {output_csv_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c39cec5"
      },
      "source": [
        "## Set up a database environment\n",
        "\n",
        "Set up a suitable environment to run SQL queries, like using a file-based SQL database (e.g., SQLite).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf0c1dfc"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the sqlite3 library and create a connection to a new SQLite database file, then create a cursor object.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0061e65f"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "\n",
        "# Create a connection to the database\n",
        "conn = sqlite3.connect('tiktok_trending.db')\n",
        "\n",
        "# Create a cursor object\n",
        "cursor = conn.cursor()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2a3a5f4"
      },
      "source": [
        "## Load the data into the database\n",
        "\n",
        "### Subtask:\n",
        "Load the prepared data into tables within the database.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a46093f3"
      },
      "source": [
        "**Reasoning**:\n",
        "Iterate through the CSV files, read them into pandas DataFrames, and load them into the SQLite database as tables.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74f6f289"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "csv_files = glob.glob('./tiktok_csv_data/*.csv')\n",
        "\n",
        "for csv_file in csv_files:\n",
        "    df = pd.read_csv(csv_file)\n",
        "    table_name = os.path.splitext(os.path.basename(csv_file))[0]\n",
        "    print(f\"Loading {csv_file} into table {table_name}...\")\n",
        "    df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
        "    print(f\"Successfully loaded {table_name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a10de19"
      },
      "source": [
        "## Perform data preprocessing with sql\n",
        "\n",
        "### Subtask:\n",
        "Use SQL queries to perform basic data cleaning and preprocessing steps.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f65a10cd"
      },
      "source": [
        "**Reasoning**:\n",
        "Inspect the schema of the tables in the database and identify columns for cleaning.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0067a020",
        "outputId": "f6e81fb2-695a-4b63-9781-2c47676f9d50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tables in the database:\n"
          ]
        }
      ],
      "source": [
        "cursor.execute(\"\") # 1. Insert query here...\n",
        "tables = cursor.fetchall()\n",
        "print(\"Tables in the database:\")\n",
        "for table in tables:\n",
        "    table_name = table[0]\n",
        "    print(f\"\\nSchema for table: {table_name}\")\n",
        "    cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
        "    schema = cursor.fetchall()\n",
        "    for col in schema:\n",
        "        print(col)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7e33cbb"
      },
      "source": [
        "**Reasoning**:\n",
        "Check for missing values in columns of interest, particularly in the 'bio' and 'stats' columns in user tables, and 'description' and 'stats' in hashtag tables.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82f36fec"
      },
      "outputs": [],
      "source": [
        "print(\"Checking for missing values in t_user table:\")\n",
        "cursor.execute(\"SELECT COUNT(*) FROM t_user WHERE bio IS NULL OR bio = '';\")\n",
        "missing_bio_t_user = cursor.fetchone()[0]\n",
        "print(f\"Missing or empty 'bio' in t_user: {missing_bio_t_user}\")\n",
        "\n",
        "cursor.execute(\"\") # 2. Insert query here...\n",
        "missing_stats_t_user = cursor.fetchone()[0]\n",
        "print(f\"Missing or empty 'stats' in t_user: {missing_stats_t_user}\")\n",
        "\n",
        "print(\"\\nChecking for missing values in m_hashtag table:\")\n",
        "cursor.execute(\"\") # 3. Insert query here...\n",
        "missing_desc_m_hashtag = cursor.fetchone()[0]\n",
        "print(f\"Missing or empty 'description' in m_hashtag: {missing_desc_m_hashtag}\")\n",
        "\n",
        "cursor.execute(\"SELECT COUNT(*) FROM m_hashtag WHERE stats IS NULL OR stats = '';\")\n",
        "missing_stats_m_hashtag = cursor.fetchone()[0]\n",
        "print(f\"Missing or empty 'stats' in m_hashtag: {missing_stats_m_hashtag}\")\n",
        "\n",
        "print(\"\\nChecking for missing values in m_music table:\")\n",
        "cursor.execute(\"\") # 4. Insert query here...\n",
        "missing_music_info_m_music = cursor.fetchone()[0]\n",
        "print(f\"Missing or empty 'musicInfo' in m_music: {missing_music_info_m_music}\")\n",
        "\n",
        "cursor.execute(\"SELECT COUNT(*) FROM m_music WHERE stats IS NULL OR stats = '';\")\n",
        "missing_stats_m_music = cursor.fetchone()[0]\n",
        "print(f\"Missing or empty 'stats' in m_music: {missing_stats_m_music}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "282ced23"
      },
      "source": [
        "**Reasoning**:\n",
        "Extract data from the nested 'stats' column in the t_user table by treating the string as JSON and creating new columns for 'followers' and 'likes'.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cae8a7d"
      },
      "outputs": [],
      "source": [
        "# Corrected UPDATE statement to extract followers and likes from the 'stats' column\n",
        "# This version handles single quotes around the keys\n",
        "cursor.execute(\"\"\"\n",
        "UPDATE t_user\n",
        "SET\n",
        "    followers = CASE\n",
        "        WHEN stats LIKE '%''followers'':%' THEN\n",
        "            CAST(SUBSTR(stats,\n",
        "                        INSTR(stats, '''followers'':') + LENGTH('''followers'':'),\n",
        "                        INSTR(SUBSTR(stats, INSTR(stats, '''followers'':') + LENGTH('''followers'':')), ',') - 1) AS INTEGER)\n",
        "        ELSE NULL\n",
        "    END,\n",
        "    likes = CASE\n",
        "        WHEN stats LIKE '%''likes'':%' THEN\n",
        "            CAST(SUBSTR(stats,\n",
        "                        INSTR(stats, '''likes'':') + LENGTH('''likes'':'),\n",
        "                        INSTR(SUBSTR(stats, INSTR(stats, '''likes'':') + LENGTH('''likes'':')), '}') - 1) AS INTEGER)\n",
        "        ELSE NULL\n",
        "    END\n",
        "WHERE stats IS NOT NULL AND stats != '';\n",
        "\"\"\")\n",
        "\n",
        "conn.commit()\n",
        "\n",
        "# Delete rows with missing or empty 'bio'\n",
        "cursor.execute(\"DELETE FROM t_user WHERE bio IS NULL OR bio = '';\")\n",
        "conn.commit()\n",
        "\n",
        "# Verify the update and deletion\n",
        "print(\"\\nVerifying extraction of followers and likes and deletion of rows with missing bio from t_user:\")\n",
        "cursor.execute(\"SELECT userId, stats, followers, likes, bio FROM t_user LIMIT 5;\")\n",
        "results = cursor.fetchall()\n",
        "for row in results:\n",
        "    print(row)\n",
        "\n",
        "print(\"\\nChecking for missing values in t_user table after cleaning:\")\n",
        "cursor.execute(\"SELECT COUNT(*) FROM t_user WHERE bio IS NULL OR bio = '';\")\n",
        "missing_bio_t_user_after = cursor.fetchone()[0]\n",
        "print(f\"Missing or empty 'bio' in t_user after cleaning: {missing_bio_t_user_after}\")\n",
        "\n",
        "cursor.execute(\"SELECT COUNT(*) FROM t_user WHERE stats IS NULL OR stats = '';\")\n",
        "missing_stats_t_user_after = cursor.fetchone()[0]\n",
        "print(f\"Missing or empty 'stats' in t_user after cleaning: {missing_stats_t_user_after}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fe768b9"
      },
      "source": [
        "## Perform exploratory data analysis with sql\n",
        "\n",
        "### Subtask:\n",
        "Use SQL queries to explore the data, calculate statistics, and identify patterns.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f05231f"
      },
      "source": [
        "**Reasoning**:\n",
        "Execute SQL queries to calculate and display the average number of followers and likes for users in the t_user table.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3c71658b"
      },
      "outputs": [],
      "source": [
        "print(\"Average followers and likes for users:\")\n",
        "cursor.execute(\"\") # 5. Insert query here...\n",
        "avg_stats = cursor.fetchone()\n",
        "print(f\"Average Followers: {avg_stats[0]:,.2f}\")\n",
        "print(f\"Average Likes: {avg_stats[1]:,.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07c03d37"
      },
      "source": [
        "**Reasoning**:\n",
        "Execute a SQL query to find and display the top 10 users with the most followers from the `t_user` table.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4005557"
      },
      "outputs": [],
      "source": [
        "print(\"\\nTop 10 users by followers:\")\n",
        "cursor.execute(\"SELECT name, followers FROM t_user ORDER BY followers DESC LIMIT 10;\")\n",
        "top_followers = cursor.fetchall()\n",
        "for user in top_followers:\n",
        "    print(f\"User: {user[0]}, Followers: {user[1]:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a541086"
      },
      "source": [
        "**Reasoning**:\n",
        "Execute a SQL query to find and display the top 10 users with the most likes from the `t_user` table, count the number of verified and unverified users, and calculate the average followers and likes for verified vs. unverified users.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5e1bf365"
      },
      "outputs": [],
      "source": [
        "print(\"\\nTop 10 users by likes:\")\n",
        "cursor.execute(\"\") # 6. Insert query here...\n",
        "top_likes = cursor.fetchall()\n",
        "for user in top_likes:\n",
        "    print(f\"User: {user[0]}, Likes: {user[1]:,}\")\n",
        "\n",
        "print(\"\\nNumber of verified and unverified users:\")\n",
        "cursor.execute(\"SELECT verified, COUNT(*) FROM t_user GROUP BY verified;\")\n",
        "verification_counts = cursor.fetchall()\n",
        "for count in verification_counts:\n",
        "    status = \"Verified\" if count[0] == 1 else \"Unverified\"\n",
        "    print(f\"{status}: {count[1]}\")\n",
        "\n",
        "print(\"\\nAverage followers and likes for verified vs. unverified users:\")\n",
        "cursor.execute(\"\") # 7. Insert query here...\n",
        "avg_stats_by_verification = cursor.fetchall()\n",
        "for stats in avg_stats_by_verification:\n",
        "    status = \"Verified\" if stats[0] == 1 else \"Unverified\"\n",
        "    print(f\"{status} - Average Followers: {stats[1]:,.2f}, Average Likes: {stats[2]:,.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "093ef4f3"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The dataset, initially in nested JSON format, was successfully converted into multiple flat CSV files (e.g., `t_user.csv`, `m_hashtag.csv`).\n",
        "*   These CSV files were successfully loaded into separate tables in a SQLite database.\n",
        "*   In the `t_user` table, 2 rows were found to have missing or empty 'bio' values. There were no missing values in the 'stats' column of `t_user`, or in the 'description', 'stats' (m\\_hashtag), 'musicInfo', or 'stats' (m\\_music) columns.\n",
        "*   Numerical data (followers, likes) was successfully extracted from the 'stats' string column in the `t_user` table using SQL string manipulation after correcting for single quotes around the keys.\n",
        "*   Rows with missing or empty 'bio' in the `t_user` table were successfully removed.\n",
        "*   The average number of followers for users in the `t_user` table is approximately 23.64 million, while the average number of likes is approximately 812.28 million.\n",
        "*   The top 10 users by followers and likes were identified, showing high engagement metrics for leading accounts.\n",
        "*   There are significantly more verified users (22) than unverified users (5) in the `t_user` table.\n",
        "*   Verified users, on average, have considerably more followers (approx. 26.8 million) and likes (approx. 928.45 million) compared to unverified users (approx. 9.74 million followers and 301.14 million likes).\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The substantial difference in average followers and likes between verified and unverified users suggests that verification status on TikTok might be strongly correlated with user popularity and engagement metrics.\n",
        "*   Further analysis could involve joining tables (e.g., users with their music or hashtags) to explore relationships between content, users, and popularity, or examining trends over time if temporal data were available.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Take Home Task\n",
        "\n",
        "Find another TikTok dataset from Kaggle (or scraping if you're more advanced) and use the similar SQL queries and the same EDA process to analyze an interesting trend in the dataset. Use aggregate statements, joins, and filtering techniques in your queries for more practice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15sUIYOiNs-6"
      },
      "source": [
        "## Answers\n",
        "1. \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
        "2. \"SELECT COUNT(*) FROM t_user WHERE stats IS NULL OR stats = '';\"\n",
        "3. \"SELECT COUNT(*) FROM m_hashtag WHERE description IS NULL OR description = '';\"\n",
        "4. \"SELECT COUNT(*) FROM m_music WHERE musicInfo IS NULL OR musicInfo = '';\"\n",
        "5. \"SELECT AVG(followers), AVG(likes) FROM t_user;\"\n",
        "6. \"SELECT name, likes FROM t_user ORDER BY likes DESC LIMIT 10;\"\n",
        "7. \"SELECT verified, AVG(followers), AVG(likes) FROM t_user GROUP BY verified;\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
